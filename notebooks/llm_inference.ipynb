{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNG\n",
      "Unfortunately, the problem does not provide an image of the food to analyze. However, I can provide a generic response based on the assumption that the image is of a standard salad with mixed greens, cherry tomatoes, cucumber, carrots, and a small amount of olive oil dressing.\n",
      "\n",
      "{calories: 150, mass: 200g, fat: 10g, carbs: 20g, protein: 5g}\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import base64\n",
    "from PIL import Image\n",
    "\n",
    "client = InferenceClient(api_key=\"\")\n",
    "\n",
    "image_path = \"../data/nutrition5k_reconstructed/images/dish_1556573514.jpeg\"\n",
    "with open(image_path, \"rb\") as f:\n",
    "    base64_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "with Image.open(image_path) as img:\n",
    "    print(img.format)\n",
    "\n",
    "image_url = f\"data:image/png;base64,{base64_image}\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a nutritionist. You will be given an image of food. Analyze the food in the image and provide its nutritional facts (calories, mass, fat, carbs, protein) in that order.\"\"\"\n",
    "        \n",
    "    },\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": \"\"\"I will provide an image of food and you will analyze the food in the image and provide its nutritional facts. Your response must strictly follow this format: {calories: <calories>, mass: <mass>, fat: <fat>, carbs: <carbs>, protein: <protein>}. Do NOT include any additional text, commentary, or explanations.\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"role\": \"assistant\",\n",
    "\t\t\"content\": \"\"\"I will answer your questions with the following format: {calories: <calories>, mass: <mass>, fat: <fat>, carbs: <carbs>, protein: <protein>}. Please provide the image of the food you would like me to analyze.\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\"text\": \"Here is an image of food I would like you to analyze.\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"image_url\",\n",
    "\t\t\t\t\"image_url\": {\"url\": image_url},\n",
    "\t\t\t}\n",
    "\t\t]\n",
    "\t}\n",
    "]\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.2-11B-Vision-Instruct\", \n",
    "\tmessages=messages, \n",
    "\tmax_tokens=500\n",
    ")\n",
    "\n",
    "response = completion.choices[0].message[\"content\"]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{calories: 88.7, mass: 76.2, fat: 3.38, carbs: 6.47, protein: 4.28}.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a nutritionist. You will be given an image of food. Analyze the food in the image and provide its nutritional facts (calories, mass, fat, carbs, protein) in that order. \"\"\"\n",
    "    },\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": \"\"\"I will provide an image of food and you will analyze the food in the image and provide its nutritional facts. Your response must strictly follow this format: {calories: <calories>, mass: <mass>, fat: <fat>, carbs: <carbs>, protein: <protein>}. Do NOT include any additional text, commentary, or explanations, and round to the nearest 4 decimals if necessary.\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"role\": \"assistant\",\n",
    "\t\t\"content\": \"\"\"I will answer your questions with the following format: {calories: <calories>, mass: <mass>, fat: <fat>, carbs: <carbs>, protein: <protein>}. Please provide the image of the food you would like me to analyze. Here is an example of the format and expected response: Example: An image of ten Olives. Response: {calories: 414, mass: 36, fat: 3.85, carbs: 2.268, protein: 0.288}. Follow the format strictly and round to the nearest 4 decimals if necessary.\"\"\"\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\"text\": \"Here is an image of food I would like you to analyze.\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"image_url\",\n",
    "\t\t\t\t\"image_url\": {\"url\": image_url},\n",
    "\t\t\t}\n",
    "\t\t]\n",
    "\t}\n",
    "]\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"meta-llama/Llama-3.2-11B-Vision-Instruct\", \n",
    "\tmessages=messages, \n",
    "\tmax_tokens=500\n",
    ")\n",
    "\n",
    "response = completion.choices[0].message[\"content\"]\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import base64\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Path\n",
    "client = InferenceClient(api_key=\"\")\n",
    "csv_path = \"../data/nutrition5k_reconstructed/metadata/test_ids.csv\"\n",
    "labels_path = \"../data/nutrition5k_reconstructed/labels/labels.csv\"\n",
    "llama_response_path = \"llama_response.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path, header=None)\n",
    "image_ids = df[0].tolist() # list of image ids in test_ids.csv\n",
    "# true labels\n",
    "label_df = pd.read_csv(labels_path, header=None)\n",
    "filtered_label_df = label_df[label_df[0].isin(image_ids)]\n",
    "id_dict = filtered_label_df.set_index(0).T.to_dict('list')\n",
    "id_dict = {key: [float(value) for value in values] for key, values in id_dict.items()}\n",
    "\n",
    "# save to csv to prevent crashing\n",
    "if os.path.exists(llama_response_path):\n",
    "    llama_response = pd.read_csv(llama_response_path, index_col=0).to_dict(orient=\"list\")\n",
    "    llama_response = {key: [float(x) for x in value] for key, value in llama_response.items()}\n",
    "else:\n",
    "    llama_response = {}\n",
    "\n",
    "# remove processed ids\n",
    "remaining_ids = [i for i in image_ids if i not in llama_response]\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_res(response):\n",
    "    try:\n",
    "        final_response = re.search(r'\\{.*\\}', response).group() # extract the response\n",
    "        if final_response:\n",
    "            values = re.findall(r\":\\s*([\\d.]+)\", final_response) # extract the values\n",
    "            final_response = [float(i) for i in values] # convert to float\n",
    "        else:\n",
    "            final_response = [0, 0, 0, 0, 0]\n",
    "    except Exception as e:\n",
    "        final_response = [0, 0, 0, 0, 0]\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59.5, 1.216, 0.038, 1.984, 0.175]\n",
      "[3.0, 100.0, 0.1, 8.3, 1.0]\n",
      "[162.0, 190.0, 7.2912, 21.6256, 5.898]\n",
      "[546.0, 134.0, 20.0, 61.0, 13.0]\n",
      "[493.8, 14.16, 2.7212, 5.0726, 4.8402]\n",
      "[800.0, 175.0, 20.36, 80.72, 41.0]\n",
      "[510.0, 45.0, 23.0, 49.0, 31.0]\n",
      "[218.0, 136.0, 10.95, 20.15, 4.13]\n",
      "[13897.34, 1391.63, 53.08, 2279.79, 261.37]\n",
      "[545.0, 44.93, 13.7, 71.264, 22.948]\n",
      "[349.4, 56.9, 18.458, 23.496, 10.896]\n",
      "[240.0, 20.0, 0.3, 45.76, 3.32]\n",
      "[466.2, 329.1, 15.4, 57.4, 37.1]\n",
      "[512.6628, 267.6614, 17.7354, 36.336, 25.668]\n",
      "[422.0, 22.0, 6.25, 37.0, 8.712]\n",
      "[120.0, 40.0, 7.8, 10.8, 3.2]\n",
      "[497.0, 277.0, 21.16, 57.639, 9.781]\n",
      "[204.0, 139.0, 11.8, 16.6, 8.67]\n",
      "[640.0, 45.0, 24.76, 55.76, 24.874]\n",
      "[70.51, 100.0, 0.08, 17.3, 1.85]\n",
      "[409.0, 99.0, 18.2, 24.4, 31.4]\n",
      "[59.0, 100.0, 0.53, 12.2, 0.77]\n",
      "[96.0, 223.0, 0.231, 6.132, 10.198]\n",
      "[276.0, 16.67, 0.0, 0.0, 40.0]\n",
      "[397.0, 195.0, 9.1425, 52.2065, 13.0475]\n",
      "[362.768, 337.373, 9.267, 44.33, 16.786]\n",
      "[408.1, 152.0, 25.8, 30.8, 16.3]\n",
      "[46.0, 27.0, 0.763, 2.847, 3.69]\n",
      "[43.0, 33.0, 0.507, 9.52, 0.646]\n",
      "[437.8, 47.6, 3.4, 5.65, 10.6]\n",
      "[270.0, 146.0, 1.2, 35.4, 8.4]\n",
      "[79.6, 52.6, 0.52, 12.72, 2.22]\n",
      "[0, 0, 0, 0, 0]\n",
      "[216.0, 28.0, 1.0, 28.0, 7.2]\n",
      "[352.0, 130.0, 4.5, 8.216, 6.642]\n",
      "[0, 0, 0, 0, 0]\n",
      "[260.0, 240.0, 12.78, 0.0, 31.0]\n",
      "[293.5, 18.5, 14.0, 23.7, 8.3]\n",
      "[4044.0, 355.0, 6.85, 407.6737, 25.9964]\n",
      "[805.0, 400.0, 31.05, 85.315, 49.8]\n",
      "[381.0, 190.0, 2.5, 22.36, 6.39]\n",
      "[252.0, 100.0, 11.0, 30.0, 10.0]\n",
      "[417.581, 201.0, 31.796, 25.079, 17.47]\n",
      "[207.0, 51.0, 0.43, 47.836, 1.461]\n",
      "[421.0, 133.0, 4.6, 57.1, 7.06]\n",
      "[0, 0, 0, 0, 0]\n",
      "[198.0, 482.0, 0.062, 50.9, 6.81]\n",
      "[0, 0, 0, 0, 0]\n",
      "[521.0, 235.6, 23.6, 43.6, 21.1]\n",
      "[286.0, 25.0, 1.1, 42.2, 0.4]\n",
      "[0, 0, 0, 0, 0]\n",
      "[18.0, 165.0, 0.0, 2.0, 0.94]\n",
      "[107.0, 0.125, 2.36, 4.375, 1.43]\n",
      "[804.71, 395.55, 29.93, 69.79, 34.54]\n",
      "[299.0, 27.0, 3.51, 12.0, 9.0]\n",
      "[100.0, 27.0, 0.002, 0.08, 0.01]\n",
      "[161.0, 125.24, 1.584, 41.967, 2.287]\n",
      "[446.0, 37.92, 2.95, 5.08, 0.71]\n",
      "[460.0, 445.86, 0.258, 64.57, 16.04]\n",
      "[268.0, 70.0, 0.8356, 14.2, 2.07]\n",
      "[63.52, 20.0, 0.004, 12.28, 0.973]\n",
      "[564.0, 230.0, 20.32, 65.245, 14.38]\n",
      "[311.0, 5.644, 1.542, 28.3, 17.444]\n",
      "[68.0, 0.189, 0.011, 0.052, 0.014]\n",
      "[560.0, 74.0, 5.63, 73.0, 18.4]\n",
      "[104.0, 226.526, 0.56, 22.847, 10.521]\n",
      "[200.0, 130.0, 8.0, 27.0, 3.0]\n",
      "[9.3, 20.1, 0.1, 0.4, 0.3]\n",
      "[65.0, 0.99, 0.04, 0.669, 0.003]\n",
      "[0, 0, 0, 0, 0]\n",
      "[356.0, 60.0, 15.0, 30.0, 10.0]\n",
      "[430.0, 46.025, 7.281, 45.633, 10.3]\n",
      "[4478.0, 4478.0, 30.41, 70.0, 44.05]\n",
      "[52.9797, 0.0832, 0.0071, 12.58, 0.3646]\n",
      "[0, 0, 0, 0, 0]\n",
      "[180.0, 90.0, 9.0, 20.0, 6.0]\n",
      "[52.0, 45.69, 0.252, 10.6, 0.909]\n",
      "[64.0, 26.0, 0.2, 12.2, 1.02]\n",
      "[414.0, 36.0, 3.85, 2.268, 0.288]\n",
      "[0, 0, 0, 0, 0]\n",
      "[236.0, 106.0, 7.31, 12.486, 22.16]\n",
      "[206.0, 0.95, 0.21, 2.1, 0.18]\n",
      "[470.0, 41.0, 8.62, 71.56, 4.56]\n",
      "[354.0, 273.0, 9.537, 54.764, 10.33]\n",
      "[720.0, 104.3, 26.4, 77.9, 34.7]\n",
      "[80.0, 46.0, 0.0, 14.0, 1.5]\n",
      "[204.0, 61.0, 14.8, 6.5, 6.3]\n",
      "[467.3, 183.0, 31.0, 13.5, 3.091]\n",
      "[56.0, 80.0, 0.0, 13.481, 0.654]\n",
      "[258.2, 110.8, 13.0, 25.6, 12.1]\n",
      "[656.0, 292.0, 47.0, 49.0, 40.0]\n",
      "[82.76, 28.88, 3.12, 12.48, 2.51]\n",
      "[492.0, 45.0, 6.0, 19.0, 3.5]\n",
      "[514.0, 160.43, 8.4559, 64.8591, 38.039]\n",
      "[62.0, 50.0, 0.05, 13.72, 0.34]\n",
      "[68.95, 27.58, 5.949, 0.0, 1.882]\n",
      "[331.0, 24.3, 2.4, 13.75, 13.18]\n",
      "[220.0, 310.0, 0.63, 20.4, 12.0]\n",
      "[123.0, 66.7, 3.8, 26.2, 2.1]\n",
      "[232.0, 169.7, 14.8, 23.7, 7.9]\n",
      "[36.0, 1.37, 2.3, 1.6, 0.7]\n",
      "[67.0, 28.0, 0.5, 16.5, 0.5]\n",
      "[0, 0, 0, 0, 0]\n",
      "[53.81, 104.23, 3.34, 7.65, 5.16]\n",
      "[219.0, 44.34, 1.74, 34.6, 4.92]\n",
      "[180.0, 125.0, 12.0, 0.5, 10.75]\n",
      "[144.0, 136.0, 2.72, 25.2, 4.4]\n",
      "[1044.96, 397.21, 43.47, 124.99, 29.13]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[406.0, 23.0, 2.0, 41.0, 4.0]\n",
      "[148.0, 109.0, 7.75, 6.342, 6.979]\n",
      "[271.16, 134.14, 7.899, 22.461, 2.829]\n",
      "[614.0, 33.5, 2.9, 19.5, 4.5]\n",
      "[615.0, 167.0, 25.9, 54.8, 39.6]\n",
      "[465.0, 388.0, 26.0, 30.0, 21.0]\n",
      "[84.12, 42.14, 3.42, 9.55, 4.26]\n",
      "[101.0, 11.04, 6.8, 0.0, 8.2]\n",
      "[288.0, 18.0, 1.72, 39.444, 1.656]\n",
      "[89.98, 53.18, 7.81, 0.35, 0.97]\n",
      "[1419.0, 278.0, 3.98, 194.181, 62.522]\n",
      "[104.0, 178.0, 1.35, 13.716, 5.985]\n",
      "[0, 0, 0, 0, 0]\n",
      "[424.0, 60.0, 28.0, 30.867, 10.188]\n",
      "[80.0, 110.0, 3.6, 11.6, 1.5]\n",
      "[36.74, 4.19, 0.115, 0.1419, 0.475]\n",
      "[215.0, 180.0, 11.676, 14.9, 10.2]\n",
      "[1066.0, 290.4, 3.3, 150.4, 36.2]\n",
      "[0, 0, 0, 0, 0]\n",
      "[5.0, 95.0, 1.0, 1.0, 1.0]\n",
      "[204.0, 72.0, 8.116, 8.976, 25.432]\n",
      "[0, 0, 0, 0, 0]\n",
      "[527.8, 365.0, 13.92, 42.52, 44.12]\n",
      "[14.4, 35.5, 0.6, 2.3, 1.0]\n",
      "[305.0, 290.0, 6.57, 46.132, 4.281]\n",
      "[153.0, 55.0, 10.0, 2.0, 12.0]\n",
      "[4426.4835, 718.4557, 427.9178, 144.5408, 123.4434]\n",
      "[126.0, 300.0, 7.471, 11.056, 3.276]\n",
      "[719.429, 277.384, 29.9771, 53.0417, 31.1094]\n",
      "[662.0, 82.0, 21.32, 42.04, 28.64]\n",
      "[432.0, 264.0, 22.08, 21.865, 26.95]\n",
      "[655.8, 174.0, 23.665, 61.314, 25.505]\n",
      "[45.0, 20.0, 2.25, 0.75, 0.25]\n",
      "[163.0, 74.0, 14.0, 20.0, 6.5]\n",
      "[379.0, 120.0, 10.2, 30.361, 23.254]\n",
      "[376.0, 50.0, 5.09, 16.441, 12.483]\n",
      "[207.0, 18.78, 1.0, 18.38, 9.37]\n",
      "[628.8, 23.7, 4.4736, 0.6272, 2.12]\n",
      "[359.0, 21.0, 2.247, 5.251, 4.943]\n",
      "[272.5, 53.5, 1.489, 26.0, 15.6]\n",
      "[402.33, 199.76, 24.48, 20.63, 17.36]\n",
      "[401.0, 40.0, 2.93, 53.84, 8.04]\n",
      "[156.0, 68.0, 10.0, 5.0, 3.7]\n",
      "[354.0, 141.0, 24.034, 16.0, 6.52]\n",
      "[235.0, 56.0, 13.758, 30.472, 7.505]\n",
      "[0, 0, 0, 0, 0]\n",
      "[238.1327, 26.0892, 0.5506, 49.4012, 3.9891]\n",
      "[960.1, 370.92, 28.6, 84.4, 114.7]\n",
      "[94.34, 68.08, 0.17, 23.56, 0.71]\n",
      "[546.0, 400.0, 29.63, 44.19, 32.27]\n",
      "[0, 0, 0, 0, 0]\n",
      "[202.0, 17.0, 0.595, 8.45, 2.238]\n",
      "[0, 0, 0, 0, 0]\n",
      "[311.9, 129.8, 9.05, 35.9, 3.9]\n",
      "[292.0, 252.0, 9.371, 20.2, 28.4]\n",
      "[120.0, 36.0, 2.0, 4.0, 4.0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[2933.55, 478.01, 171.442, 253.452, 142.104]\n",
      "[376.19, 142.0, 0.3979, 86.0711, 10.3494]\n",
      "[23.0, 23.0, 0.0, 5.6, 0.3]\n",
      "[312.6, 53.815, 9.758, 44.85, 6.395]\n",
      "[504.94, 243.4, 12.84, 42.97, 49.91]\n",
      "[425.0, 34.52, 3.108, 1.608, 0.235]\n",
      "[190.0, 123.0, 5.96, 17.42, 13.73]\n",
      "[241.0, 1828.0, 142.66, 201.875, 198.2867]\n",
      "[187.0, 43.0, 7.45, 17.477, 8.045]\n",
      "[260.6, 85.1, 17.1, 27.2, 5.2]\n",
      "[146.25, 21.88, 10.75, 0.36, 11.03]\n",
      "[130.0, 99.0, 9.65, 1.589, 12.293]\n",
      "[258.0, 99.0, 13.0, 5.0, 19.0]\n",
      "[250.0, 60.0, 7.9, 30.0, 10.0]\n",
      "[238.0, 43.2, 6.11, 13.072, 5.312]\n",
      "[74.51, 1.05, 0.0257, 19.05, 0.288]\n",
      "[44.0, 0.34, 0.26, 0.25, 0.02]\n",
      "[92.0, 1.8, 0.07, 0.0, 1.0]\n",
      "[150.0, 2.0, 1.25, 5.0, 5.0]\n",
      "[528.0, 53.0, 63.45, 3.068, 1.88]\n",
      "[628.0, 44.96, 15.875, 5.03, 9.491]\n",
      "[513.0, 46.0, 24.111, 8.015, 27.301]\n",
      "[454.0, 30.83, 17.73, 32.47, 37.95]\n",
      "[390.0, 128.8, 12.7, 37.4, 16.1]\n",
      "[817.17, 407.708, 33.94, 68.147, 37.891]\n",
      "[31.0, 173.0, 0.8416, 4.0962, 1.4685]\n",
      "[334.0, 75.0, 4.9, 49.7, 11.2]\n",
      "[75.0, 110.0, 0.191, 17.332, 0.566]\n",
      "[202.0, 191.0, 0.79, 29.53, 14.95]\n",
      "[442.835, 550.0, 34.5786, 23.34, 34.008]\n",
      "[725.263, 151.473, 17.369, 119.576, 37.235]\n",
      "[114.0, 670.8, 43.04, 67.98, 29.96]\n",
      "[230.0, 143.0, 1.5, 35.9, 7.5]\n",
      "[378.227, 273.559, 19.365, 10.756, 28.182]\n",
      "[487.9281, 105.506586862929, 27.6547136642223, 73.7809820693976, 28.754362666678]\n",
      "[413.28, 35.0, 2.6, 7.65, 9.333]\n",
      "[229.0, 200.0, 13.0, 24.0, 4.0]\n",
      "[159.0, 145.0, 7.97, 10.958, 5.331]\n",
      "[120.0, 50.0, 0.9, 6.299, 2.0]\n",
      "[354.0, 67.56, 6.39, 24.74, 12.45]\n",
      "[161.92, 81.28, 4.42, 0.55, 28.92]\n",
      "[127.44, 270.6, 0.28, 31.74, 4.09]\n",
      "[200.0, 64.0, 11.0, 20.0, 4.4]\n",
      "[300.0, 250.0, 15.0, 20.0, 20.0]\n",
      "[493.649, 258.45, 13.087, 64.712, 18.362]\n",
      "[0, 0, 0, 0, 0]\n",
      "[105.0, 51.0, 4.081, 3.3, 12.437]\n",
      "[2.38, 41.11, 0.0, 0.0274, 0.56]\n",
      "[0, 0, 0, 0, 0]\n",
      "[271.0, 199.0, 13.64, 25.13, 8.056]\n",
      "[76.0, 8.0, 0.16, 3.2, 0.21]\n",
      "[271.0, 206.5, 7.6562, 40.3984, 8.87]\n",
      "[678.0, 72.0, 4.912, 9.792, 0.944]\n",
      "[452.0, 57.0, 1.671, 76.42, 4.82]\n",
      "[1265.2, 262.94, 32.76, 149.85, 70.5]\n",
      "[144.0, 80.0, 9.0, 18.0, 6.0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[12.0, 5.0, 0.21, 1.836, 0.311]\n",
      "[360.0, 18.9, 11.4, 6.4, 2.9]\n",
      "[44.07, 14.0, 0.288, 7.902, 0.615]\n",
      "[550.0, 47.0, 34.84, 63.25, 14.01]\n",
      "[456.0, 172.8, 26.56, 38.99, 14.98]\n",
      "[15.0, 30.0, 0.0226, 1.9043, 1.3997]\n",
      "[43.0, 46.0, 0.774, 9.586, 1.039]\n",
      "[0, 0, 0, 0, 0]\n",
      "[495.0, 32.0, 2.09, 3.97, 0.8625]\n",
      "[360.0, 31.74, 4.36, 25.448, 17.924]\n",
      "[290.0, 170.0, 13.0, 3.0, 26.0]\n",
      "[273.0, 57.5, 7.14, 10.85, 20.14]\n",
      "[400.0, 80.0, 23.94, 10.45, 25.61]\n",
      "[0, 0, 0, 0, 0]\n",
      "[394.0, 227.77, 15.62, 45.72, 30.23]\n",
      "[0, 0, 0, 0, 0]\n",
      "[384.0, 21.3, 17.48, 10.9, 7.059]\n",
      "[490.86, 32.0, 2.8, 10.49, 2.937]\n",
      "[52.0, 0.127, 0.047, 0.0975, 0.375]\n",
      "[239.2336, 163.843, 9.017, 23.0364, 15.5584]\n",
      "[90.0, 123.0, 5.284, 6.479, 3.013]\n",
      "[158.75, 170.8870740951918, 9.820492737062121, 19.02682019318033, 7.244654493387878]\n",
      "[760.0, 70.0, 4.8, 10.1, 3.1]\n",
      "[234.0, 190.0, 12.2, 30.8, 15.5]\n",
      "[26.27, 52.95, 0.06, 2.876, 0.506]\n",
      "[180.0, 100.0, 1.2, 10.0, 5.0]\n",
      "[467.5, 37.2, 4.98, 3.51, 1.375]\n",
      "[235.0, 48.0, 9.45, 10.384, 7.0]\n",
      "[256.0, 300.0, 21.0, 23.0, 5.5]\n",
      "[501.0, 230.0, 15.88, 46.44, 30.7]\n",
      "[84.6, 51.63, 6.872, 0.0, 4.3]\n",
      "[292.0, 138.0, 4.13, 25.22, 7.29]\n",
      "[120.0, 0.16, 0.07, 2.15, 0.32]\n",
      "[390.5, 62.97, 3.51, 87.85, 6.304]\n",
      "[312.0, 230.0, 19.0, 20.0, 20.0]\n",
      "[677.5, 600.0, 26.0315, 69.0674, 16.5128]\n",
      "[94.0, 122.0, 1.0, 21.36, 1.53]\n",
      "[150.0, 200.0, 10.0, 30.0, 20.0]\n",
      "[86.0, 100.0, 1.62, 21.0, 3.1]\n",
      "[1622.06, 1164.13, 217.92, 531.36, 93.5]\n",
      "[260.0, 285.0, 1.25, 51.75, 1.25]\n",
      "[648.37, 241.3, 33.56, 26.99, 34.24]\n",
      "[43.0, 35.0, 0.802, 8.935, 1.319]\n",
      "[53.0, 94.0, 0.9, 10.8, 1.2]\n",
      "[56.0, 84.5, 0.038, 10.481, 4.0]\n",
      "[306.0, 6.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 6.0, 0.02, 1.4, 0.26]\n",
      "[14.0, 28.0, 0.137, 0.866, 1.528]\n",
      "[523.0, 383.0, 24.02, 33.987, 23.211]\n",
      "[390.0, 26.9, 10.4, 39.8, 9.4]\n",
      "[192.46, 38.47, 0.79, 37.95, 2.56]\n",
      "[2829.0, 95.3, 80.155, 100.0, 135.3]\n",
      "[132.0, 266.0, 5.2, 29.3, 3.6]\n",
      "[266.77, 22.64, 1.725, 21.03, 5.556]\n",
      "[166.0, 70.0, 0.742, 17.388, 2.284]\n",
      "[17.0, 0.535, 0.0, 3.77, 0.56]\n",
      "[121.0, 250.0, 1.97, 27.29, 4.51]\n",
      "[584.51, 264.17, 28.44, 56.75, 31.01]\n",
      "[340.0, 202.576, 25.682, 40.0, 9.258]\n",
      "[465.829, 69.7018, 15.426, 50.829, 19.7018]\n",
      "[374.66, 88.196, 3.0315, 34.1386, 4.3687]\n",
      "[414.0, 36.0, 3.85, 2.268, 0.288]\n",
      "[204.99, 16.0, 1.342, 1.0915, 0.1339]\n",
      "[283.0, 213.0, 11.1, 31.6, 9.9]\n",
      "[200.0, 100.0, 10.0, 20.0, 10.0]\n",
      "[2918.0, 920.6, 225.2, 166.871, 31.342]\n",
      "[121.0, 127.0, 2.6, 10.4, 4.8]\n",
      "[268.0, 16.0, 2.5, 2.958, 0.87]\n",
      "[510.0, 53.7, 31.969, 15.54, 12.006]\n",
      "[62.69, 80.7, 0.895, 13.302, 0.989]\n",
      "[410.0, 43.0, 4.1, 46.0, 35.0]\n",
      "[135.0, 100.0, 4.0, 10.0, 5.0]\n",
      "[277.5, 68.3, 2.332, 27.28, 4.0]\n",
      "[215.0, 200.0, 11.3, 16.9, 13.0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[67.0, 196.0, 4.688, 6.16, 2.896]\n",
      "[139.987, 72.8, 1.6, 8.99, 18.9797]\n",
      "[102.0, 9.0, 0.568, 22.527, 1.662]\n",
      "[93.0, 75.0, 2.5, 13.75, 2.75]\n",
      "[60.0, 0.071, 0.013, 14.5, 1.0]\n",
      "[141.0, 170.0, 11.276, 7.26, 3.28]\n",
      "[471.0, 41.41, 0.024, 108.413, 6.668]\n",
      "[420.0, 150.0, 20.0, 10.0, 20.0]\n",
      "[1412.52, 41.74, 64.77, 184.311, 40.928]\n",
      "[94.0, 12.0, 1.02, 2.452, 1.482]\n",
      "[550.0, 120.0, 17.6, 45.5, 22.0]\n",
      "[225.0, 184.0, 12.0, 23.5, 10.7]\n",
      "[147.0, 48.0, 11.068, 0.275, 3.205]\n",
      "[494.312, 299.453, 34.641, 55.721, 33.332]\n",
      "[638.0, 62.8, 38.1, 0.0, 33.9]\n",
      "[442.0, 113.0, 13.35, 26.76, 39.63]\n",
      "[75.0, 96.0, 0.0, 15.0, 3.0]\n",
      "[571.495, 124.576, 34.021, 59.104, 26.201]\n",
      "[381.8, 218.0, 23.2, 27.5, 18.8]\n",
      "[377.9825, 76.4652, 5.3084, 46.0653, 13.3673]\n",
      "[131.0, 66.04, 0.64, 10.31, 2.92]\n",
      "[0, 0, 0, 0, 0]\n",
      "[528.0, 170.5, 1.47, 104.16, 27.55]\n",
      "[109.8, 60.0, 0.174, 21.24, 2.056]\n",
      "[285.0, 120.0, 19.1, 2.4, 16.6]\n",
      "[180.0, 161.0, 0.81, 15.6, 4.5]\n",
      "[530.0, 46.7, 33.5, 21.2, 16.5]\n",
      "[466.0, 186.0, 31.3, 13.416, 8.156]\n",
      "[88.1, 159.3, 0.3456, 13.89, 4.093]\n",
      "[62.0, 78.3, 0.73, 5.268, 1.804]\n",
      "[65.1, 0.165, 0.215, 15.296, 0.576]\n",
      "[172.0, 199.0, 10.8, 15.0, 5.5]\n",
      "[0, 0, 0, 0, 0]\n",
      "[343.0, 104.92, 17.332, 18.32, 24.72]\n",
      "[720.55, 1051.0, 52.58, 51.284, 73.59]\n",
      "[0, 0, 0, 0, 0]\n",
      "[497.0, 460.1, 24.78, 34.745, 35.566]\n",
      "[192.0, 220.0, 0.743, 24.091, 3.2]\n",
      "[350.0, 56.5, 8.0, 29.5, 13.5]\n",
      "[439.0, 50.19, 4.68, 2.68, 27.94]\n",
      "[222.0, 165.0, 0.0, 48.55, 2.67]\n",
      "[114.0, 87.0, 6.85, 7.861, 1.637]\n",
      "[198.4788, 56.3738, 2.8483, 21.7683, 6.7917]\n",
      "[442.59, 39.45, 2.51, 2.754, 0.558]\n",
      "[575.95, 185.12, 43.66, 4.97, 54.17]\n",
      "[120.0, 50.0, 6.2, 14.0, 5.551]\n",
      "[52.2, 0.1708, 0.107, 12.8, 0.343]\n",
      "[274.0, 300.0, 0.077, 6.0, 14.0]\n",
      "[233.0, 57.6861, 9.7815, 7.6193, 17.3904]\n",
      "[280.0, 28.0, 28.0, 0.0, 0.0]\n",
      "[47.50125, 84.75, 0.08, 12.5, 0.459]\n",
      "[405.0, 341.0, 15.31, 45.41, 12.54]\n",
      "[164.0, 164.0, 4.7, 20.0, 4.2]\n",
      "[387.0, 415.0, 19.05, 19.47, 23.99]\n",
      "[20.0, 40.0, 26.819, 2.5, 5.0, 3.1108, 1.2, 1.0, 2.0, 1.4447, 1.0]\n",
      "[514.88, 50.0, 10.81, 69.355, 4.907]\n"
     ]
    },
    {
     "ename": "HfHubHTTPError",
     "evalue": "424 Client Error: Failed Dependency for url: https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-11B-Vision-Instruct/v1/chat/completions (Request ID: nmt3fkzRhz1FoA5nhye9b)\n\nRequest failed during generation: Server error:",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/csci2470/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/csci2470/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 424 Client Error: Failed Dependency for url: https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-11B-Vision-Instruct/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 42\u001b[0m\n\u001b[1;32m     11\u001b[0m image_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata:image/png;base64,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase64_image\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     {\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     }\n\u001b[1;32m     39\u001b[0m ]\n\u001b[0;32m---> 42\u001b[0m completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     43\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-3.2-11B-Vision-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     44\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages, \n\u001b[1;32m     45\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     48\u001b[0m response \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# get response\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/csci2470/lib/python3.11/site-packages/huggingface_hub/inference/_client.py:882\u001b[0m, in \u001b[0;36mInferenceClient.chat_completion\u001b[0;34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p)\u001b[0m\n\u001b[1;32m    860\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    861\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m    862\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    879\u001b[0m     stream_options\u001b[38;5;241m=\u001b[39mstream_options,\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m payload \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m payload\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m--> 882\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost(model\u001b[38;5;241m=\u001b[39mmodel_url, json\u001b[38;5;241m=\u001b[39mpayload, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/csci2470/lib/python3.11/site-packages/huggingface_hub/inference/_client.py:296\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m     hf_raise_for_status(response)\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/anaconda3/envs/csci2470/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:477\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 424 Client Error: Failed Dependency for url: https://api-inference.huggingface.co/models/meta-llama/Llama-3.2-11B-Vision-Instruct/v1/chat/completions (Request ID: nmt3fkzRhz1FoA5nhye9b)\n\nRequest failed during generation: Server error:"
     ]
    }
   ],
   "source": [
    "for i in remaining_ids:\n",
    "    if count == 10:\n",
    "        pd.DataFrame.from_dict(llama_response, orient=\"index\").to_csv(llama_response_path)\n",
    "        time.sleep(120)\n",
    "        count = 0\n",
    "    \n",
    "    image_path = \"../data/nutrition5k_reconstructed/images/\" + i + \".jpeg\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        base64_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "    image_url = f\"data:image/png;base64,{base64_image}\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a nutritionist. You will be given an image of food. Analyze the food in the image and provide its nutritional facts (calories, mass, fat, carbs, protein) in that order. \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"I will provide an image of food and you will analyze the food in the image and provide its nutritional facts. Your response must strictly follow this format: {calories: <calories>, mass: <mass>, fat: <fat>, carbs: <carbs>, protein: <protein>}. Do NOT include any additional text, commentary, or explanations, and round to the nearest 4 decimals if necessary.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"\"\"I will answer your questions with the following format: {calories: <calories>, mass: <mass>, fat: <fat>, carbs: <carbs>, protein: <protein>}. Please provide the image of the food you would like me to analyze. Here is an example of the format and expected response: Example: An image of ten Olives. Response: {calories: 414, mass: 36, fat: 3.85, carbs: 2.268, protein: 0.288}. Follow the format strictly and round to the nearest 4 decimals if necessary.\"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Don't tell me your thinking process, give a best estimate. Here is an image of food I would like you to analyze. Remember to follow the format, no explanation. \"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\"url\": image_url},\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-11B-Vision-Instruct\", \n",
    "        messages=messages, \n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message[\"content\"] # get response\n",
    "    if response == \"\":\n",
    "        llama_response[i] = [0, 0, 0, 0, 0]\n",
    "    else:\n",
    "        final_response = parse_res(response)\n",
    "        llama_response[i] = final_response\n",
    "        if llama_response[i] == []:\n",
    "            llama_response[i] = [0, 0, 0, 0, 0] # if no prediction from llama, placeholder value\n",
    "        print(llama_response[i])\n",
    "    count += 1\n",
    "\n",
    "pd.DataFrame.from_dict(llama_response, orient=\"index\").to_csv(llama_response_path) # save to csv again\n",
    "\n",
    "mae_scores = {key: mean_absolute_error(id_dict[key], llama_response[key]) for key in llama_response if key in id_dict}\n",
    "all_truth_value = []\n",
    "all_pred_value = []\n",
    "for key in llama_response:\n",
    "    if key in id_dict:\n",
    "        all_truth_value.extend(id_dict[key])\n",
    "        all_pred_value.extend(llama_response[key])\n",
    "overall_mae = mean_absolute_error(all_truth_value, all_pred_value)\n",
    "\n",
    "print(overall_mae)\n",
    "print(mae_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.6870951895533\n",
      "[273.96479428 156.50676837  13.92178545  29.47684831  14.56527954]\n"
     ]
    }
   ],
   "source": [
    "# llama response has 360 elements\n",
    "import numpy as np\n",
    "sub_dict = {}\n",
    "for i in llama_response.keys():\n",
    "    sub_dict[i] = id_dict[i]\n",
    "\n",
    "true_mat = []\n",
    "pred_mat = []\n",
    "for key in llama_response:\n",
    "    if key in sub_dict:\n",
    "        true_values = sub_dict[key]\n",
    "        pred_values = llama_response[key]\n",
    "        if len(true_values) != len(pred_values):\n",
    "            pred_values = pred_values[:len(true_values)]\n",
    "        true_mat.append(true_values)\n",
    "        pred_mat.append(pred_values)\n",
    "\n",
    "true_mat = np.array(true_mat)\n",
    "pred_mat = np.array(pred_mat)\n",
    "\n",
    "column_mae = np.mean(np.abs(true_mat - pred_mat), axis=0)\n",
    "overall_mae = mean_absolute_error(true_mat.flatten(), pred_mat.flatten())\n",
    "print(overall_mae)\n",
    "print(column_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci2470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
