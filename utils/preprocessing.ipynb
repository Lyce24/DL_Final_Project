{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 299, 299])\n",
      "tensor(298.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "\n",
    "def load_images(image_path, transform = None):\n",
    "    image_dict = {}\n",
    "    for img in os.listdir(image_path):\n",
    "        idx = img.split('.')[0]\n",
    "        abs_path = os.path.join(image_path, img)\n",
    "        img = Image.open(abs_path).convert('RGB')\n",
    "        img = transform(img)\n",
    "        image_dict[idx] = img\n",
    "    return image_dict\n",
    "\n",
    "dataset_path = '../../data/nutrition5k_reconstructed/'\n",
    "prepared_path = './data'\n",
    "\n",
    "image_path = os.path.join(dataset_path, 'images')\n",
    "train_labels = os.path.join(prepared_path, 'train_labels.csv')\n",
    "val_labels= os.path.join(prepared_path, 'val_labels.csv')\n",
    "test_labels = os.path.join(prepared_path, 'test_labels.csv')\n",
    "mass_inputs = os.path.join(prepared_path, 'mass_inputs.csv')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_images = load_images(image_path, transform)\n",
    "print(train_images['dish_1561666849'].shape)\n",
    "\n",
    "\n",
    "def load_masses(file_path):\n",
    "    mass_dict = {}\n",
    "    df = pd.read_csv(file_path)\n",
    "    for idx, row in df.iterrows():\n",
    "        mass_dict[row['id']] = torch.tensor(row['mass'])\n",
    "        \n",
    "    return mass_dict\n",
    "\n",
    "mass_dict = load_masses(mass_inputs)\n",
    "print(mass_dict['dish_1561666849'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2755, 3, 299, 299])\n",
      "torch.Size([2755])\n",
      "torch.Size([2755, 4])\n",
      "torch.Size([32, 3, 299, 299])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 4])\n"
     ]
    }
   ],
   "source": [
    "# Load the DataFrame once\n",
    "df = pd.read_csv(train_labels)\n",
    "\n",
    "# Extract IDs\n",
    "ids = df['id'].values\n",
    "\n",
    "# Prepare inputs and labels\n",
    "inputs = torch.stack([train_images[idx] for idx in ids])\n",
    "labels = torch.tensor(df.drop(columns=['id', 'mass']).values, dtype=torch.float32)\n",
    "\n",
    "masses = torch.tensor([mass_dict[idx] for idx in ids], dtype=torch.float32)\n",
    "dataset = TensorDataset(inputs, masses, labels)\n",
    "\n",
    "# Create the DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(inputs.size())\n",
    "print(masses.size())\n",
    "print(labels.size())\n",
    "\n",
    "# print the shape of the first batch\n",
    "for batch in dataloader:\n",
    "    print(batch[0].size())\n",
    "    print(batch[1].size())\n",
    "    print(batch[2].size())\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci2470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
