{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 299, 299]) torch.Size([32, 1]) torch.Size([32, 4])\n",
      "torch.Size([32, 3, 299, 299]) torch.Size([32, 1]) torch.Size([32, 4])\n",
      "torch.Size([32, 3, 299, 299]) torch.Size([32, 1]) torch.Size([32, 4])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from utils.preprocess import prepare_dataloaders\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Resize to Inception-compatible dimensions\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize if needed\n",
    "])\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "dataset_path = '../data/nutrition5k_reconstructed/'\n",
    "prepared_path = './utils/data'\n",
    "\n",
    "image_path = os.path.join(dataset_path, 'images')\n",
    "train_labels = os.path.join(prepared_path, 'train_labels.csv')\n",
    "val_labels= os.path.join(prepared_path, 'val_labels.csv')\n",
    "test_labels = os.path.join(prepared_path, 'test_labels.csv')\n",
    "mass_inputs = os.path.join(prepared_path, 'mass_inputs.csv')\n",
    "\n",
    "train_loader, val_loader, test_loader = prepare_dataloaders(image_path, mass_inputs, train_labels, val_labels, test_labels, transform, batch_size = 32, shuffle = True, mass = True)\n",
    "for (train_batch, val_batch, test_batch) in zip(train_loader, val_loader, test_loader):\n",
    "    print(train_batch[0].shape, train_batch[1].shape, train_batch[2].shape)\n",
    "    print(val_batch[0].shape, val_batch[1].shape, val_batch[2].shape)\n",
    "    print(test_batch[0].shape, test_batch[1].shape, test_batch[2].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Define the InceptionV2 backbone\n",
    "class InceptionV2Backbone(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(InceptionV2Backbone, self).__init__()\n",
    "        # Use InceptionV3 as a proxy for InceptionV2\n",
    "        self.backbone = models.inception_v3(pretrained=pretrained, aux_logits=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the classification head\n",
    "\n",
    "    def forward(self, x):\n",
    "        # When aux_logits=True, the output is a tuple: (main_output, aux_output)\n",
    "        x = self.backbone(x)\n",
    "        if isinstance(x, tuple):  # Extract the main output\n",
    "            x = x[0]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NutritionModel(nn.Module):\n",
    "    def __init__(self, num_tasks=3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_tasks: Number of tasks (calories, macronutrients, and mass).\n",
    "        \"\"\"\n",
    "        super(NutritionModel, self).__init__()\n",
    "        self.backbone = InceptionV2Backbone()  # Use the corrected backbone\n",
    "        \n",
    "        # Shared image feature layers\n",
    "        self.shared_fc1 = nn.Linear(2048, 4096)\n",
    "        self.shared_fc2 = nn.Linear(4096, 4096)\n",
    "        \n",
    "        # Mass input processing\n",
    "        self.mass_fc1 = nn.Linear(1, 128)\n",
    "        self.mass_fc2 = nn.Linear(128, 256)\n",
    "        \n",
    "        # Task-specific heads\n",
    "        self.task_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(4096 + 256, 4096),  # Adjust input size to account for concatenation\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4096, 1)\n",
    "            ) for _ in range(num_tasks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, image, mass):\n",
    "        # Process the image through the backbone\n",
    "        image_features = self.backbone(image)\n",
    "        image_features = nn.functional.relu(self.shared_fc1(image_features))\n",
    "        image_features = nn.functional.relu(self.shared_fc2(image_features))\n",
    "        \n",
    "        # Process the mass input\n",
    "        mass_features = nn.functional.relu(self.mass_fc1(mass))\n",
    "        mass_features = nn.functional.relu(self.mass_fc2(mass_features))\n",
    "        \n",
    "        # Concatenate image and mass features\n",
    "        combined_features = torch.cat([image_features, mass_features], dim=1)\n",
    "        \n",
    "        # Pass through task-specific heads\n",
    "        outputs = [task_head(combined_features) for task_head in self.task_heads]\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the loss function for multi-task learning\n",
    "# def multi_task_loss(predictions, targets):\n",
    "#     \"\"\"\n",
    "#     Args:\n",
    "#         predictions: Tensor of shape (batch_size, num_tasks).\n",
    "#         targets: Tensor of shape (batch_size, num_tasks).\n",
    "#     Returns:\n",
    "#         Combined loss for all tasks.\n",
    "#     \"\"\"\n",
    "#     losses = torch.abs(predictions - targets)  # Mean Absolute Error (MAE)\n",
    "#     return losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, \n",
    "    dataloader, \n",
    "    val_dataloader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs=50, \n",
    "    save_path=\"best_model.pth\"\n",
    "):\n",
    "    model = model.to(device)  # Move model to device\n",
    "    current_best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            # Unpack and move data to device\n",
    "            images, masses, targets = (data.to(device) for data in batch)\n",
    "\n",
    "            # Forward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, masses)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                images, masses, targets = (data.to(device) for data in batch)\n",
    "                outputs = model(images, masses)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if avg_val_loss < current_best_loss:\n",
    "            current_best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model improved. Saved at epoch {epoch + 1} with validation loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "        \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the model\n",
    "model = NutritionModel(num_tasks=4)  # Predicting 4 outputs: calories, fat, carbs, protein\n",
    "\n",
    "loss_fn = nn.MSELoss()  # Mean Squared Error (MSE) loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Train the model (testing with 1 epoch)\n",
    "train_model(model, train_loader, loss_fn, optimizer, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yliu802/miniconda3/envs/csci2470/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/yliu802/miniconda3/envs/csci2470/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_518883/361127027.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "[[5.2857315e+01 2.5471659e+00 3.9730988e+00 1.0896251e+00]\n",
      " [5.1330708e+01 1.5975579e+00 4.1416597e+00 9.8164767e-01]\n",
      " [6.1485149e+01 2.8130555e-01 1.2798719e+01 1.3858711e+00]\n",
      " [3.1589348e+01 6.2669200e-01 1.4806970e+00 6.3902992e-01]\n",
      " [7.8282733e+02 4.1500912e+01 4.0511253e+01 5.1395893e+01]\n",
      " [5.2753632e+02 2.7451101e+01 2.9004736e+01 3.7224117e+01]\n",
      " [2.3498866e+02 2.7696066e+00 3.1352003e+01 1.3369636e+01]\n",
      " [3.6531082e+02 1.8845421e+01 2.0279406e+01 2.7657698e+01]\n",
      " [3.3646085e+02 1.7050840e+01 1.9057165e+01 2.6817871e+01]\n",
      " [5.2395947e+02 4.7897747e+01 1.7891827e+01 2.4275877e+01]]\n",
      "MAE Results:\n",
      "Calories: MAE = 60.8842, MAE (%) = 23.28%\n",
      "Fat: MAE = 6.2410, MAE (%) = 47.09%\n",
      "Carb: MAE = 9.3452, MAE (%) = 46.14%\n",
      "Protein: MAE = 7.0701, MAE (%) = 38.43%\n"
     ]
    }
   ],
   "source": [
    "# load the model from model.pth\n",
    "model = NutritionModel(num_tasks=4)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def test_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Tests the model and calculates MAE for each nutritional fact.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model to evaluate.\n",
    "        dataloader (DataLoader): DataLoader for the test dataset.\n",
    "    \n",
    "    Returns:\n",
    "        dict: MAE for each nutritional fact.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masses, targets in dataloader:\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            masses = masses.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            outputs = model(images, masses)\n",
    "\n",
    "            # Store predictions and targets\n",
    "            all_predictions.append(outputs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Concatenate all predictions and targets\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    # print a few predictions\n",
    "    print(all_predictions[:10])\n",
    "    all_targets = np.concatenate(all_targets, axis=0)\n",
    "\n",
    "    # Calculate MAE and MAE percentage for each nutritional fact\n",
    "    results = {}\n",
    "    nutritional_facts = [\"calories\", \"fat\", \"carb\", \"protein\"]\n",
    "    for i, fact in enumerate(nutritional_facts):\n",
    "        mae = mean_absolute_error(all_targets[:, i], all_predictions[:, i])\n",
    "        mean_value = np.mean(all_targets[:, i])\n",
    "        mae_percent = (mae / mean_value) * 100 if mean_value != 0 else 0\n",
    "        results[fact] = {\n",
    "            \"MAE\": mae,\n",
    "            \"MAE (%)\": mae_percent\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "print(\"Evaluating the model...\")\n",
    "results = test_model(model, test_loader)\n",
    "print(\"MAE Results:\")\n",
    "for fact, metrics in results.items():\n",
    "    print(f\"{fact.capitalize()}: MAE = {metrics['MAE']:.4f}, MAE (%) = {metrics['MAE (%)']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci2470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
