{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 299, 299])\n",
      "torch.Size([16, 5])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.dirname(os.getcwd())\n",
    "sys.path.append(path)\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from utils.preprocess import load_data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "IMG_DIMN = 299\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "dataset_path = '../../data/nutrition5k_reconstructed/'\n",
    "prepared_path = '../utils/data'\n",
    "\n",
    "image_path = os.path.join(dataset_path, 'images')\n",
    "train_labels = os.path.join(prepared_path, 'train_labels.csv')\n",
    "val_labels = os.path.join(prepared_path, 'val_labels.csv')\n",
    "\n",
    "df_train = pd.read_csv(train_labels)\n",
    "df_val = pd.read_csv(val_labels)\n",
    "\n",
    "labels = [\"calories\", \"mass\", \"fat\", \"carb\", \"protein\"]\n",
    "train_loader, val_loader = load_data(df_train=df_train, df_val=df_val, image_path=image_path, labels = labels, img_dim = IMG_DIMN, batch_size=BATCH_SIZE)\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2048])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import inception_v3, Inception_V3_Weights\n",
    "\n",
    "# Define the InceptionV3 backbone\n",
    "class InceptionV3(nn.Module):\n",
    "    def __init__(self, weights=Inception_V3_Weights.DEFAULT):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            weights: Pre-trained weights to use for the InceptionV3 model. Use `None` for no pre-training.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Load the InceptionV3 model with specified weights\n",
    "        self.backbone = inception_v3(weights=weights, aux_logits=True)\n",
    "        self.backbone.fc = nn.Identity()  # Remove the classification head\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # When aux_logits=True, the output is a tuple: (main_output, aux_output)\n",
    "        x = self.backbone(x)\n",
    "        return x[0] if isinstance(x, tuple) else x\n",
    "\n",
    "# test the forward pass\n",
    "model = InceptionV3()\n",
    "x = torch.randn(16, 3, 299, 299)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1])\n",
      "Number of trainable parameters: 134213325\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "class NutritionModel(nn.Module):\n",
    "    def __init__(self, tasks : List[str]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_tasks: Number of tasks (calories, macronutrients, and mass).\n",
    "        \"\"\"\n",
    "        super(NutritionModel, self).__init__()\n",
    "        self.backbone = InceptionV3()  # Use the corrected backbone\n",
    "        \n",
    "        # Shared image feature layers\n",
    "        self.shared_fc1 = nn.Linear(2048, 4096) # Use 2048 as input size as InceptionV3 has 2048 output features\n",
    "        self.shared_fc2 = nn.Linear(4096, 4096)\n",
    "        \n",
    "        \n",
    "        # Task-specific heads\n",
    "        self.task_heads = nn.ModuleDict({\n",
    "            task: nn.Sequential(\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4096, 1)\n",
    "            ) for task in tasks\n",
    "        })\n",
    "\n",
    "    def forward(self, image):\n",
    "        # Process the image through the backbone\n",
    "        image_features = self.backbone(image)\n",
    "        image_features = nn.functional.relu(self.shared_fc1(image_features))\n",
    "        image_features = nn.functional.relu(self.shared_fc2(image_features))\n",
    "        \n",
    "        # Pass through task-specific heads\n",
    "        outputs = {task: head(image_features) for task, head in self.task_heads.items()}        \n",
    "        return outputs\n",
    "            \n",
    "# print the model\n",
    "tasks = [\"calories\", \"mass\", \"fat\", \"carb\", \"protein\"]\n",
    "\n",
    "model = NutritionModel(tasks)\n",
    "# print how many parameters the model has\n",
    "x = torch.randn(16, 3, 299, 299)\n",
    "y_bar = model(x)\n",
    "print(y_bar[\"calories\"].shape)\n",
    "\n",
    "# Print the number of trainable parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, epochs, checkpoint_path):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate loss for all tasks\n",
    "            loss = sum(mse_loss(outputs[key].squeeze(), targets[:, i])\n",
    "                       for i, key in enumerate(outputs.keys()))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss, ind_loss = validate_model(model, val_loader)\n",
    "        ind_loss_str = \", \".join([f\"{key}: {val:.4f}\" for key, val in ind_loss.items()])\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader)}, Val Loss: {val_loss}, Ind Loss: {ind_loss_str}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(\"Model saved\")\n",
    "            \n",
    "def validate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    # individual losses for each task\n",
    "    losses = {key: 0.0 for key in model.task_heads.keys()}\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            for i, key in enumerate(outputs.keys()):\n",
    "                loss = mse_loss(outputs[key].squeeze(), targets[:, i])\n",
    "                losses[key] += loss.item()\n",
    "            \n",
    "            val_loss += sum(losses.values())\n",
    "            \n",
    "    for key in losses.keys():\n",
    "        losses[key] /= len(val_loader)\n",
    "        \n",
    "    return val_loss / len(val_loader), losses\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the model\n",
    "tasks = [\"calories\", \"mass\", \"fat\", \"carb\", \"protein\"]\n",
    "\n",
    "model = NutritionModel(tasks).to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()  # Mean Squared Error (MSE) loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Train the model (testing with 1 epoch)\n",
    "train_model(model, train_loader, val_loader, epochs=5, checkpoint_path=\"./checkpoints/paper.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci2470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
